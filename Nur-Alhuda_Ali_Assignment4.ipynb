{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 4: Pipelines and Hyperparameter Tuning (32 total marks)\n",
    "### Due: November 22 at 11:59pm\n",
    "\n",
    "### Name: Nur-Alhuda Ali"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will be putting together everything you have learned so far. You will need to find your own dataset, do all the appropriate preprocessing, test different supervised learning models and evaluate the results. More details for each step can be found below.\n",
    "\n",
    "### You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "## Step 1: Data Input (4 marks)\n",
    "\n",
    "Import the dataset you will be using. You can download the dataset onto your computer and read it in using pandas, or download it directly from the website. Answer the questions below about the dataset you selected. \n",
    "\n",
    "To find a dataset, you can use the resources listed in the notes. The dataset can be numerical, categorical, text-based or mixed. If you want help finding a particular dataset related to your interests, please email the instructor.\n",
    "\n",
    "**You cannot use a dataset that was used for a previous assignment or in class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 891, 'name': 'CDC Diabetes Health Indicators', 'repository_url': 'https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators', 'data_url': 'https://archive.ics.uci.edu/static/public/891/data.csv', 'abstract': 'The Diabetes Health Indicators Dataset contains healthcare statistics and lifestyle survey information about people in general along with their diagnosis of diabetes. The 35 features consist of some demographics, lab test results, and answers to survey questions for each patient. The target variable for classification is whether a patient has diabetes, is pre-diabetic, or healthy. ', 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Tabular', 'Multivariate'], 'num_instances': 253680, 'num_features': 21, 'feature_types': ['Categorical', 'Integer'], 'demographics': ['Sex', 'Age', 'Education Level', 'Income'], 'target_col': ['Diabetes_binary'], 'index_col': ['ID'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2017, 'last_updated': 'Fri Nov 03 2023', 'dataset_doi': '10.24432/C53919', 'creators': [], 'intro_paper': {'title': 'Incidence of End-Stage Renal Disease Attributed to Diabetes Among Persons with Diagnosed Diabetes — United States and Puerto Rico, 2000–2014', 'authors': 'Nilka Rios Burrows, MPH; Israel Hora, PhD; Linda S. Geiss, MA; Edward W. Gregg, PhD; Ann Albright, PhD', 'published_in': 'Morbidity and Mortality Weekly Report', 'year': 2017, 'url': 'https://www.cdc.gov/mmwr/volumes/66/wr/mm6643a2.htm', 'doi': None}, 'additional_info': {'summary': 'Dataset link: https://www.cdc.gov/brfss/annual_data/annual_2014.html', 'purpose': 'To better understand the relationship between  lifestyle and diabetes in the US', 'funded_by': 'The CDC', 'instances_represent': 'Each row represents a person participating in this study.', 'recommended_data_splits': 'Cross validation or a fixed train-test split could be used.', 'sensitive_data': '- Gender\\n- Income\\n- Education level', 'preprocessing_description': 'Bucketing of age', 'variable_info': '- Diabetes diagnosis\\n- Demographics (race, sex)\\n- Personal information (income, educations)\\n- Health history (drinking, smoking, mental health, physical health)', 'citation': None}, 'external_url': 'https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset'}\n",
      "                    name     role     type      demographic  \\\n",
      "0                     ID       ID  Integer             None   \n",
      "1        Diabetes_binary   Target   Binary             None   \n",
      "2                 HighBP  Feature   Binary             None   \n",
      "3               HighChol  Feature   Binary             None   \n",
      "4              CholCheck  Feature   Binary             None   \n",
      "5                    BMI  Feature  Integer             None   \n",
      "6                 Smoker  Feature   Binary             None   \n",
      "7                 Stroke  Feature   Binary             None   \n",
      "8   HeartDiseaseorAttack  Feature   Binary             None   \n",
      "9           PhysActivity  Feature   Binary             None   \n",
      "10                Fruits  Feature   Binary             None   \n",
      "11               Veggies  Feature   Binary             None   \n",
      "12     HvyAlcoholConsump  Feature   Binary             None   \n",
      "13         AnyHealthcare  Feature   Binary             None   \n",
      "14           NoDocbcCost  Feature   Binary             None   \n",
      "15               GenHlth  Feature  Integer             None   \n",
      "16              MentHlth  Feature  Integer             None   \n",
      "17              PhysHlth  Feature  Integer             None   \n",
      "18              DiffWalk  Feature   Binary             None   \n",
      "19                   Sex  Feature   Binary              Sex   \n",
      "20                   Age  Feature  Integer              Age   \n",
      "21             Education  Feature  Integer  Education Level   \n",
      "22                Income  Feature  Integer           Income   \n",
      "\n",
      "                                          description units missing_values  \n",
      "0                                          Patient ID  None             no  \n",
      "1         0 = no diabetes 1 = prediabetes or diabetes  None             no  \n",
      "2                          0 = no high BP 1 = high BP  None             no  \n",
      "3        0 = no high cholesterol 1 = high cholesterol  None             no  \n",
      "4   0 = no cholesterol check in 5 years 1 = yes ch...  None             no  \n",
      "5                                     Body Mass Index  None             no  \n",
      "6   Have you smoked at least 100 cigarettes in you...  None             no  \n",
      "7        (Ever told) you had a stroke. 0 = no 1 = yes  None             no  \n",
      "8   coronary heart disease (CHD) or myocardial inf...  None             no  \n",
      "9   physical activity in past 30 days - not includ...  None             no  \n",
      "10  Consume Fruit 1 or more times per day 0 = no 1...  None             no  \n",
      "11  Consume Vegetables 1 or more times per day 0 =...  None             no  \n",
      "12  Heavy drinkers (adult men having more than 14 ...  None             no  \n",
      "13  Have any kind of health care coverage, includi...  None             no  \n",
      "14  Was there a time in the past 12 months when yo...  None             no  \n",
      "15  Would you say that in general your health is: ...  None             no  \n",
      "16  Now thinking about your mental health, which i...  None             no  \n",
      "17  Now thinking about your physical health, which...  None             no  \n",
      "18  Do you have serious difficulty walking or clim...  None             no  \n",
      "19                                0 = female 1 = male  None             no  \n",
      "20  13-level age category (_AGEG5YR see codebook) ...  None             no  \n",
      "21  Education level (EDUCA see codebook) scale 1-6...  None             no  \n",
      "22  Income scale (INCOME2 see codebook) scale 1-8 ...  None             no  \n"
     ]
    }
   ],
   "source": [
    "# Import dataset (1 mark)\n",
    "\n",
    "# If not installed, use --> pip install ucimlrepo\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "diabetes = fetch_ucirepo(id=891) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = diabetes.data.features \n",
    "y = diabetes.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(diabetes.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(diabetes.variables) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20316765",
   "metadata": {},
   "source": [
    "### Questions (3 marks)\n",
    "\n",
    "1. (1 mark) What is the source of your dataset?\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators\n",
    "\n",
    "2. (1 mark) Why did you pick this particular dataset?\n",
    "\n",
    "I picked this dataset because diabetes runs in my family and I think it would be cool to create a model that I could test on me and my family members.\n",
    "\n",
    "3. (1 mark) Was there anything challenging about finding a dataset that you wanted to use?\n",
    "\n",
    "No, there wasn't. I knew I wanted to use a classification dataset for diabetes since it runs in my family.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "## Step 2: Data Processing (5 marks)\n",
    "\n",
    "The next step is to process your data. Implement the following steps as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23814686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Feature Matrix:  (253680, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HighBP  HighChol  CholCheck  BMI  Smoker  Stroke  HeartDiseaseorAttack  \\\n",
       "0       1         1          1   40       1       0                     0   \n",
       "1       0         0          0   25       1       0                     0   \n",
       "2       1         1          1   28       0       0                     0   \n",
       "3       1         0          1   27       0       0                     0   \n",
       "4       1         1          1   24       0       0                     0   \n",
       "\n",
       "   PhysActivity  Fruits  Veggies  ...  AnyHealthcare  NoDocbcCost  GenHlth  \\\n",
       "0             0       0        1  ...              1            0        5   \n",
       "1             1       0        0  ...              0            1        3   \n",
       "2             0       1        0  ...              1            1        5   \n",
       "3             1       1        1  ...              1            0        2   \n",
       "4             1       1        1  ...              1            0        2   \n",
       "\n",
       "   MentHlth  PhysHlth  DiffWalk  Sex  Age  Education  Income  \n",
       "0        18        15         1    0    9          4       3  \n",
       "1         0         0         0    0    7          6       1  \n",
       "2        30        30         1    0    9          4       8  \n",
       "3         0         0         0    0   11          3       6  \n",
       "4         3         0         0    0   11          5       4  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at size of dataset and first few rows to look at features\n",
    "print(\"Size of Feature Matrix: \", X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9182120f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Target Vector:  (253680, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary\n",
       "0                0\n",
       "1                0\n",
       "2                0\n",
       "3                0\n",
       "4                0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Size of Target Vector: \", y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bff0909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.429001</td>\n",
       "      <td>0.424121</td>\n",
       "      <td>0.962670</td>\n",
       "      <td>28.382364</td>\n",
       "      <td>0.443169</td>\n",
       "      <td>0.040571</td>\n",
       "      <td>0.094186</td>\n",
       "      <td>0.756544</td>\n",
       "      <td>0.634256</td>\n",
       "      <td>0.811420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951053</td>\n",
       "      <td>0.084177</td>\n",
       "      <td>2.511392</td>\n",
       "      <td>3.184772</td>\n",
       "      <td>4.242081</td>\n",
       "      <td>0.168224</td>\n",
       "      <td>0.440342</td>\n",
       "      <td>8.032119</td>\n",
       "      <td>5.050434</td>\n",
       "      <td>6.053875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.494934</td>\n",
       "      <td>0.494210</td>\n",
       "      <td>0.189571</td>\n",
       "      <td>6.608694</td>\n",
       "      <td>0.496761</td>\n",
       "      <td>0.197294</td>\n",
       "      <td>0.292087</td>\n",
       "      <td>0.429169</td>\n",
       "      <td>0.481639</td>\n",
       "      <td>0.391175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215759</td>\n",
       "      <td>0.277654</td>\n",
       "      <td>1.068477</td>\n",
       "      <td>7.412847</td>\n",
       "      <td>8.717951</td>\n",
       "      <td>0.374066</td>\n",
       "      <td>0.496429</td>\n",
       "      <td>3.054220</td>\n",
       "      <td>0.985774</td>\n",
       "      <td>2.071148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              HighBP       HighChol      CholCheck            BMI  \\\n",
       "count  253680.000000  253680.000000  253680.000000  253680.000000   \n",
       "mean        0.429001       0.424121       0.962670      28.382364   \n",
       "std         0.494934       0.494210       0.189571       6.608694   \n",
       "min         0.000000       0.000000       0.000000      12.000000   \n",
       "25%         0.000000       0.000000       1.000000      24.000000   \n",
       "50%         0.000000       0.000000       1.000000      27.000000   \n",
       "75%         1.000000       1.000000       1.000000      31.000000   \n",
       "max         1.000000       1.000000       1.000000      98.000000   \n",
       "\n",
       "              Smoker         Stroke  HeartDiseaseorAttack   PhysActivity  \\\n",
       "count  253680.000000  253680.000000         253680.000000  253680.000000   \n",
       "mean        0.443169       0.040571              0.094186       0.756544   \n",
       "std         0.496761       0.197294              0.292087       0.429169   \n",
       "min         0.000000       0.000000              0.000000       0.000000   \n",
       "25%         0.000000       0.000000              0.000000       1.000000   \n",
       "50%         0.000000       0.000000              0.000000       1.000000   \n",
       "75%         1.000000       0.000000              0.000000       1.000000   \n",
       "max         1.000000       1.000000              1.000000       1.000000   \n",
       "\n",
       "              Fruits        Veggies  ...  AnyHealthcare    NoDocbcCost  \\\n",
       "count  253680.000000  253680.000000  ...  253680.000000  253680.000000   \n",
       "mean        0.634256       0.811420  ...       0.951053       0.084177   \n",
       "std         0.481639       0.391175  ...       0.215759       0.277654   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       1.000000  ...       1.000000       0.000000   \n",
       "50%         1.000000       1.000000  ...       1.000000       0.000000   \n",
       "75%         1.000000       1.000000  ...       1.000000       0.000000   \n",
       "max         1.000000       1.000000  ...       1.000000       1.000000   \n",
       "\n",
       "             GenHlth       MentHlth       PhysHlth       DiffWalk  \\\n",
       "count  253680.000000  253680.000000  253680.000000  253680.000000   \n",
       "mean        2.511392       3.184772       4.242081       0.168224   \n",
       "std         1.068477       7.412847       8.717951       0.374066   \n",
       "min         1.000000       0.000000       0.000000       0.000000   \n",
       "25%         2.000000       0.000000       0.000000       0.000000   \n",
       "50%         2.000000       0.000000       0.000000       0.000000   \n",
       "75%         3.000000       2.000000       3.000000       0.000000   \n",
       "max         5.000000      30.000000      30.000000       1.000000   \n",
       "\n",
       "                 Sex            Age      Education         Income  \n",
       "count  253680.000000  253680.000000  253680.000000  253680.000000  \n",
       "mean        0.440342       8.032119       5.050434       6.053875  \n",
       "std         0.496429       3.054220       0.985774       2.071148  \n",
       "min         0.000000       1.000000       1.000000       1.000000  \n",
       "25%         0.000000       6.000000       4.000000       5.000000  \n",
       "50%         0.000000       8.000000       5.000000       7.000000  \n",
       "75%         1.000000      10.000000       6.000000       8.000000  \n",
       "max         1.000000      13.000000       6.000000       8.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get general statistics for the data.\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afc244d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HighBP                  int64\n",
      "HighChol                int64\n",
      "CholCheck               int64\n",
      "BMI                     int64\n",
      "Smoker                  int64\n",
      "Stroke                  int64\n",
      "HeartDiseaseorAttack    int64\n",
      "PhysActivity            int64\n",
      "Fruits                  int64\n",
      "Veggies                 int64\n",
      "HvyAlcoholConsump       int64\n",
      "AnyHealthcare           int64\n",
      "NoDocbcCost             int64\n",
      "GenHlth                 int64\n",
      "MentHlth                int64\n",
      "PhysHlth                int64\n",
      "DiffWalk                int64\n",
      "Sex                     int64\n",
      "Age                     int64\n",
      "Education               int64\n",
      "Income                  int64\n",
      "dtype: object\n",
      "\n",
      "Number of nulls in feature matrix:\n",
      " HighBP                  0\n",
      "HighChol                0\n",
      "CholCheck               0\n",
      "BMI                     0\n",
      "Smoker                  0\n",
      "Stroke                  0\n",
      "HeartDiseaseorAttack    0\n",
      "PhysActivity            0\n",
      "Fruits                  0\n",
      "Veggies                 0\n",
      "HvyAlcoholConsump       0\n",
      "AnyHealthcare           0\n",
      "NoDocbcCost             0\n",
      "GenHlth                 0\n",
      "MentHlth                0\n",
      "PhysHlth                0\n",
      "DiffWalk                0\n",
      "Sex                     0\n",
      "Age                     0\n",
      "Education               0\n",
      "Income                  0\n",
      "dtype: int64\n",
      "\n",
      "Number of nulls in target vector:  Diabetes_binary    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Clean data (if needed)\n",
    "\n",
    "# Check for null values.\n",
    "print(X.dtypes)\n",
    "print(\"\\nNumber of nulls in feature matrix:\\n\", X.isnull().sum())\n",
    "print(\"\\nNumber of nulls in target vector: \", y.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "181db989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70a8c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement preprocessing steps. Remember to use ColumnTransformer if more than one preprocessing method is needed\n",
    "\n",
    "# For features that are binary, 0 or 1 values, no encoding is necessary.\n",
    "# Apply ordinal encoding to these features since they are ordered & categorical but not binary: GenHlth, Age, Education, Income\n",
    "\n",
    "# TRY WITHOUT SCALING FIRST.\n",
    "# Using ColumnTransformer in case I end up adding a scaler if performance needs to be improved.\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ct = ColumnTransformer(\n",
    "    [(\"ordenc\", OrdinalEncoder(), ['GenHlth', 'Age', 'Education', 'Income'])\n",
    "    ])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b92c46b7",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "\n",
    "1. (1 mark) Were there any missing/null values in your dataset? If yes, how did you replace them and why? If no, describe how you would've replaced them and why.\n",
    "\n",
    "There were no missing values. If there were any missing values, I would have deleted all rows in the dataset that contain missing values since all but 3 features, 'BMI', 'MentHlth', and 'PhysHlth', are categorical and there is no reasonable way to fill in missing values from existing data.\n",
    "\n",
    "2. (1 mark) What type of data do you have? What preprocessing methods would you have to apply based on your data types?\n",
    "\n",
    "My dataset consists of 21 features, all but 7 are binary. Of these 7 features of type integer, 4, 'GenHlth', 'Age', 'Education', 'Income', are categorical - each integer represents are category of the feature. These categorical features of type integer must be encoded using OrdinalEncoding since their categories have an order to them. The remaining 3 integer type features, 'BMI', 'MentHlth', and 'PhysHlth', are numerical. Since 'BMI' typically does not have a wide range of values, I will first implement the models without scaling it. Since the values for 'MentHlth' and 'PhysHlth' represent days and are contained within a scale of 1 to 30 days, which is important for the interpretation of the features, I have decided not to scale these 2 features. The target vector is of binary type with 0 indicating no diabetes and 1 indicating pre-diabetes/diabetes; therefore, no encoding is needed.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "## Step 3: Implement Machine Learning Model (11 marks)\n",
    "\n",
    "In this section, you will implement three different supervised learning models (one linear and two non-linear) of your choice. You will use a pipeline to help you decide which model and hyperparameters work best. It is up to you to select what models to use and what hyperparameters to test. You can use the class examples for guidance. You must print out the best model parameters and results after the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5558a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement pipeline and grid search here. Can add more code blocks if necessary\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline_lr = Pipeline([('preprocessing', ct), ('clsf', LogisticRegression(max_iter=1000))])\n",
    "pipeline_kn = Pipeline([('preprocessing', ct), ('clsf', KNeighborsClassifier())])\n",
    "pipeline_rf = Pipeline([('preprocessing', ct), ('clsf', RandomForestClassifier(random_state=0))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd61685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Grids\n",
    "param_grid_lr = {'clsf__C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "param_grid_kn = {'clsf__n_neighbors': [1, 3, 5, 7],\n",
    "                 'clsf__weights': ['uniform', 'distance']}\n",
    "param_grid_rf = {'clsf__n_estimators': [100, 200, 300],\n",
    "                 'clsf__max_depth': [5, 10, 15]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "def3cceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;ordenc&#x27;,\n",
       "                                                                         OrdinalEncoder(),\n",
       "                                                                         [&#x27;GenHlth&#x27;,\n",
       "                                                                          &#x27;Age&#x27;,\n",
       "                                                                          &#x27;Education&#x27;,\n",
       "                                                                          &#x27;Income&#x27;])])),\n",
       "                                       (&#x27;clsf&#x27;,\n",
       "                                        RandomForestClassifier(random_state=0))]),\n",
       "             param_grid={&#x27;clsf__max_depth&#x27;: [5, 10, 15],\n",
       "                         &#x27;clsf__n_estimators&#x27;: [100, 200, 300]},\n",
       "             return_train_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;ordenc&#x27;,\n",
       "                                                                         OrdinalEncoder(),\n",
       "                                                                         [&#x27;GenHlth&#x27;,\n",
       "                                                                          &#x27;Age&#x27;,\n",
       "                                                                          &#x27;Education&#x27;,\n",
       "                                                                          &#x27;Income&#x27;])])),\n",
       "                                       (&#x27;clsf&#x27;,\n",
       "                                        RandomForestClassifier(random_state=0))]),\n",
       "             param_grid={&#x27;clsf__max_depth&#x27;: [5, 10, 15],\n",
       "                         &#x27;clsf__n_estimators&#x27;: [100, 200, 300]},\n",
       "             return_train_score=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;ordenc&#x27;, OrdinalEncoder(),\n",
       "                                                  [&#x27;GenHlth&#x27;, &#x27;Age&#x27;,\n",
       "                                                   &#x27;Education&#x27;, &#x27;Income&#x27;])])),\n",
       "                (&#x27;clsf&#x27;, RandomForestClassifier(random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;ordenc&#x27;, OrdinalEncoder(),\n",
       "                                 [&#x27;GenHlth&#x27;, &#x27;Age&#x27;, &#x27;Education&#x27;, &#x27;Income&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ordenc</label><div class=\"sk-toggleable__content\"><pre>[&#x27;GenHlth&#x27;, &#x27;Age&#x27;, &#x27;Education&#x27;, &#x27;Income&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessing',\n",
       "                                        ColumnTransformer(transformers=[('ordenc',\n",
       "                                                                         OrdinalEncoder(),\n",
       "                                                                         ['GenHlth',\n",
       "                                                                          'Age',\n",
       "                                                                          'Education',\n",
       "                                                                          'Income'])])),\n",
       "                                       ('clsf',\n",
       "                                        RandomForestClassifier(random_state=0))]),\n",
       "             param_grid={'clsf__max_depth': [5, 10, 15],\n",
       "                         'clsf__n_estimators': [100, 200, 300]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search\n",
    "grid_search_lr = GridSearchCV(pipeline_lr, param_grid_lr, cv=5, return_train_score=True)\n",
    "grid_search_lr.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "grid_search_kn = GridSearchCV(pipeline_kn, param_grid_kn, cv=5, return_train_score=True)\n",
    "grid_search_kn.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "grid_search_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=5, return_train_score=True)\n",
    "grid_search_rf.fit(X_train, y_train.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0578b9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "Best parameters: {'clsf__C': 0.001}\n",
      "Best cross-validation score: 0.858\n",
      "\n",
      "K-Nearest Neighbors Results:\n",
      "Best parameters: {'clsf__n_neighbors': 7, 'clsf__weights': 'uniform'}\n",
      "Best cross-validation score: 0.847\n",
      "\n",
      "Random Forest Results:\n",
      "Best parameters: {'clsf__max_depth': 5, 'clsf__n_estimators': 100}\n",
      "Best cross-validation score: 0.862\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Results:\")\n",
    "print(\"Best parameters: {}\".format(grid_search_lr.best_params_))\n",
    "print(\"Best cross-validation score: {:.3f}\".format(grid_search_lr.best_score_))\n",
    "\n",
    "print(\"\\nK-Nearest Neighbors Results:\")\n",
    "print(\"Best parameters: {}\".format(grid_search_kn.best_params_))\n",
    "print(\"Best cross-validation score: {:.3f}\".format(grid_search_kn.best_score_))\n",
    "\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(\"Best parameters: {}\".format(grid_search_rf.best_params_))\n",
    "print(\"Best cross-validation score: {:.3f}\".format(grid_search_rf.best_score_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3dbd7075",
   "metadata": {},
   "source": [
    "### Questions (5 marks)\n",
    "\n",
    "1. (1 mark) Do you need regression or classification models for your dataset?\n",
    "\n",
    "I need classification models for my dataset to predict the target variable as 0 (non-diabetic) or 1 (pre-diabetic or diabetic).\n",
    "\n",
    "2. (2 marks) Which models did you select for testing and why?\n",
    "\n",
    "I selected Logistic Regression as the linear model since it is the most commmonly used model for linear classification. For non-linear models, I wanted to use either K-Nearest Neighbours or Naive Bayes since they were both new models that we never implemented in our assignments before. However, since Naive Bayes usually performs worse than linear classifiers, I eliminated it and opted for K-Nearest Neighbours instead. The other non-linear model I chose was Random Forest because it generally has a high performance. \n",
    "\n",
    "3. (2 marks) Which model worked the best? Does this make sense based on the theory discussed in the course and the context of your dataset?\n",
    "\n",
    "Although the other 2 models scored very similarly, the Random Forest Classifier performed the best, with a training accuracy of 86.2% at 100 n_estimators and a max_depth of 5. This does not agree with what was discussed in the course, as we learned that larger is always better for random forests since it reduces overfitting. This discrepancy could indicate that there could be an issue with the dataset, like a class imbalance, as indicated in the source for this dataset, causing the model to become overly fitted to the majority class and perform poorly on the minority class, especially considering that the other models' training accuracies seemed to cap at the about the same number."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "## Step 4: Validate Model (6 marks)\n",
    "\n",
    "Use the testing set to calculate the testing accuracy for the best model determined in Step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69e64c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy of Random Forest Classifier: 0.858\n"
     ]
    }
   ],
   "source": [
    "# Calculate testing accuracy (1 mark)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_model = grid_search_rf.best_estimator_ \n",
    "y_pred = best_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Testing Accuracy of Random Forest Classifier: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e4529ba",
   "metadata": {},
   "source": [
    "\n",
    "### Questions (5 marks)\n",
    "\n",
    "1. (1 mark) Which accuracy metric did you choose? \n",
    "\n",
    "I used the accuracy as a metric for the model's performance, as speicfied by the instructions, which simply represents how correct the model is in its predictions.\n",
    "\n",
    "2. (1 mark) How do these results compare to those in part 3? Did this model generalize well?\n",
    "\n",
    "The testing accuracy is 85.8%, which is ever so slightly lower than the training accuracy. This means that the model does not generalize well and could mean the model underfits the data (is a high-bias model) and needs to be more complex. However, since it is confirmed from the source of this dataset that it is imbalanced, the more likely cause is that if one class appears more than the other in the dataset, that imbalance was present in both the training and testing set, causing the testing accuracy to be almost the same as the training accuracy.\n",
    "\n",
    "3. (3 marks) Based on your results and the context of your dataset, did the best model perform \"well enough\" to be used out in the real-world? Why or why not? Do you have any suggestions for how you could improve this analysis?\n",
    "\n",
    "No, the model did not perform well enough to be used in the real world because due to the imbalance in the dataset, the model is better trained to predict the majority class than the minority one. I would improve the model by handling the class imbalance, which could be done by oversampling (randomly duplicating samples from the minority class) or decreasing the weight of the majority class and increasing the weight of the minority class using the 'class_weight' parameter when initializing the Random Forest Classifier."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "## Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "1. I referenced the lecture examples for preprocessing, including scaling, encoding, column transformer, tuning, and pipelines.\n",
    "\n",
    "2. I completed the steps in order the first time. Then I went back to make test some additional classifier models and found that they produced the similar results, which led me to realise that the issue was with the imbalanced dataset.\n",
    "\n",
    "3. I did not use generative AI for any code. However, I did use it (ChatGPT) to understand how similar training and testing accuracies could be a result of an imbalanced dataset using the prompt \"How does an imbalanced classification dataset cause a model to have the same score for training and testing?\"\n",
    "\n",
    "4. The main challenge I faced was coming to understand why my model not only seemed to cap at a certain training score and went against what we learned in class, but also why its training and testing scores were virtually the same. It took testing many additional models to finally realise that the issue could be with the data quality. This led me to look into the dataset further and my suspicion that the dataset was imbalanced was confirmed by the source I got it from. ChatGPT helped me understand how an imbalanced dataset affects model performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challenging, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "I found it challenging to understand why my model was not performing the way I expected since I hadn't come across anything like this in the course prior to this assignment. I liked that this assignment allowed me to implement every step of the machine learning process on my own and to think critically about the preprocessing steps that are necessary for my particular dataset and what models are suitable for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c3b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
